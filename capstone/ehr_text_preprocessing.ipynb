{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM, Dropout, BatchNormalization, Masking\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import seaborn as sns\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라벨 데이터 작업\n",
    " - No Finding : 특이 점을 찾지 못한 경우\n",
    "    - 반대의 경우는 특이 점을 찾은 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227827 entries, 0 to 227826\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype\n",
      "---  ------    --------------   -----\n",
      " 0   study_id  227827 non-null  int64\n",
      " 1   Finding   227827 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 3.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19164\\2816991744.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_data_noFinding['No Finding'] = label_data_noFinding['No Finding'].fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19164\\2816991744.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_data_noFinding['Finding'] = label_data_noFinding['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n"
     ]
    }
   ],
   "source": [
    "label_data_path = './data/mimic-cxr-2.0.0-chexpert.csv'\n",
    "\n",
    "label_data_csv = pd.read_csv(label_data_path)\n",
    "# 필요 없는 피처 필터링\n",
    "label_data_filter = label_data_csv.drop(columns=['subject_id', 'Support Devices'])\n",
    "\n",
    "label_data_filter = label_data_filter.fillna(0)\n",
    "\n",
    "label_data_noFinding = label_data_filter[['study_id', 'No Finding']]\n",
    "label_data_noFinding['No Finding'] = label_data_noFinding['No Finding'].fillna(0)\n",
    "\n",
    "label_data_noFinding['Finding'] = label_data_noFinding['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "label_data_Finding = label_data_noFinding[['study_id', 'Finding']]\n",
    "\n",
    "label_data_Finding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  Finding\n",
       "0  50414267        0\n",
       "1  53189527        0\n",
       "2  53911762        0\n",
       "3  56699142        0\n",
       "4  57375967        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data_Finding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# null 값 확인 \n",
    " - 50%가 넘는 데이터가 남게 됨 (impression, findings)\n",
    " - 11,000 여개 정도의 데이터가 남게 되며 위를 학습시켜도 무난할 것이라 예상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10464\n"
     ]
    }
   ],
   "source": [
    "ehr_csv_data_path = './data/findings_and_impression.csv'\n",
    "\n",
    "ehr_data_csv = pd.read_csv(ehr_csv_data_path)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(ehr_data_csv)):\n",
    "    if pd.isnull(ehr_data_csv['Findings'].iloc[i]) or pd.isnull(ehr_data_csv['Impression'].iloc[i]):\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 널 값이 있는 행을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50414267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53189527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53911762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56699142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57375967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11720</th>\n",
       "      <td>56459556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>57060480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11722</th>\n",
       "      <td>52257272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>52341872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11724</th>\n",
       "      <td>56958909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       study_id  Finding\n",
       "0      50414267        0\n",
       "1      53189527        0\n",
       "2      53911762        0\n",
       "3      56699142        0\n",
       "4      57375967        1\n",
       "...         ...      ...\n",
       "11720  56459556        1\n",
       "11721  57060480        0\n",
       "11722  52257272        0\n",
       "11723  52341872        0\n",
       "11724  56958909        0\n",
       "\n",
       "[11725 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehr_data_csv_filtered = ehr_data_csv.dropna()\n",
    "\n",
    "merge_data_frame = pd.merge(ehr_data_csv_filtered, label_data_Finding, on=\"study_id\")\n",
    "\n",
    "merge_data_frame[['study_id', 'Finding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no focal consolidation, pleural effusion or pneumothorax.  Bilateral\n",
      " nodular opacities that most likely represent nipple shadows. The\n",
      " cardiomediastinal silhouette is normal.  Clips project over the left lung,\n",
      " potentially within the breast. The imaged upper abdomen is unremarkable.\n",
      " Chronic deformity of the posterior left sixth and seventh ribs are noted.\n",
      "\n",
      "No acute cardiopulmonary process.\n"
     ]
    }
   ],
   "source": [
    "findings_lst = []\n",
    "ehr_data_csv_filtered['Findings'].astype('str')\n",
    "for string in ehr_data_csv_filtered['Findings']:\n",
    "    findings_lst.append(string)\n",
    "\n",
    "impression_lst = []\n",
    "ehr_data_csv_filtered['Impression'].astype('str')\n",
    "for string in ehr_data_csv_filtered['Impression']:\n",
    "    impression_lst.append(string)\n",
    "\n",
    "print(findings_lst[0], end='\\n')\n",
    "print()\n",
    "print(impression_lst[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    " - 1. ___ -> name 변수로 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no focal consolidation, pleural effusion or pneumothorax.  Bilateral\n",
      " nodular opacities that most likely represent nipple shadows. The\n",
      " cardiomediastinal silhouette is normal.  Clips project over the left lung,\n",
      " potentially within the breast. The imaged upper abdomen is unremarkable.\n",
      " Chronic deformity of the posterior left sixth and seventh ribs are noted.\n",
      "No acute cardiopulmonary process.\n"
     ]
    }
   ],
   "source": [
    "# ___ -> name 으로 변환\n",
    "def replace_data(texts):\n",
    "    special_char = \"___\"\n",
    "    return texts.replace(special_char, \"name\")\n",
    "\n",
    "\n",
    "replace_finding_lst = []\n",
    "for i in range(len(findings_lst)):\n",
    "    replace_finding_lst.append(replace_data(findings_lst[i]))\n",
    "\n",
    "replace_impression_lst = []\n",
    "for i in range(len(impression_lst)):\n",
    "    replace_impression_lst.append(replace_data(impression_lst[i]))\n",
    "\n",
    "print(replace_finding_lst[0], end='\\n')\n",
    "print(replace_impression_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(replace_finding_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규식 표현을 통한 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is no focal consolidation pleural effusion or pneumothorax bilateral nodular opacities that most likely represent nipple shadows the cardiomediastinal silhouette is normal clips project over the left lung potentially within the breast the imaged upper abdomen is unremarkable chronic deformity of the posterior left sixth and seventh ribs are noted \n"
     ]
    }
   ],
   "source": [
    "# 모든 텍스트 소문자변환, 특수문자 정규표현식을 제거\n",
    "def re_text_preprocessing(lst):\n",
    "     re_cleaned_list = []\n",
    "     for text in lst:\n",
    "          text = text.lower()\n",
    "          words = text.split()\n",
    "          refine_text = \"\"\n",
    "          for word in words:\n",
    "               refine_text += word + ' '\n",
    "          re_cleaned_text = re.sub(r'[^\\w\\s]', '', refine_text)\n",
    "          re_cleaned_list.append(re_cleaned_text)\n",
    "     return re_cleaned_list\n",
    "\n",
    "replace_finding_lst = re_text_preprocessing(replace_finding_lst)\n",
    "\n",
    "print(replace_finding_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거\n",
    "    - 불용어가 제거된 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 :  there is no focal consolidation pleural effusion or pneumothorax bilateral nodular opacities that most likely represent nipple shadows the cardiomediastinal silhouette is normal clips project over the left lung potentially within the breast the imaged upper abdomen is unremarkable chronic deformity of the posterior left sixth and seventh ribs are noted \n",
      "불용어 제거 후 :  focal consolidation pleural effusion pneumothorax bilateral nodular opacities likely represent nipple shadows cardiomediastinal silhouette normal clips project left lung potentially within breast imaged upper abdomen unremarkable chronic deformity posterior left sixth seventh ribs noted \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 불용어 제거\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(texts):\n",
    "    rm_sw_text = \"\"\n",
    "    words = texts.split()\n",
    "    filtered_text = \"\"\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_text += word + ' '\n",
    "    rm_sw_text += filtered_text\n",
    "    return rm_sw_text \n",
    "\n",
    "replace_finding_lst_v2 = []\n",
    "for idx in range(len(replace_finding_lst)):\n",
    "    replace_finding_lst_v2.append(remove_stopwords(replace_finding_lst[idx]))\n",
    "# 완성된 문장 집합\n",
    "print(\"불용어 제거 전 : \", replace_finding_lst[0])\n",
    "print(\"불용어 제거 후 : \", replace_finding_lst_v2[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 학습된 토크나이저 사용\n",
    " - 참고 레퍼런스 : https://wikidocs.net/166801\n",
    " - 트레인 셋과 테스트 셋 분할\n",
    " - 사전 학습 토큰화의 단어 어휘 개수 : 28996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 의료계에서 사용하는 토큰화 모델\n",
    "tokenizer_model_name = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_name)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화된 문장들 텐서로 변환\n",
    " - 문장들 텐서로 변환 시킨 것을 input\n",
    " - Finding 피처를 label\n",
    "### 시퀀스분석\n",
    " - 문장 시퀀스화 할 경우 최대 길이 = 1472\n",
    "  - maxlen = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805\n"
     ]
    }
   ],
   "source": [
    "tokens_list = []\n",
    "for text in replace_finding_lst:\n",
    "    tokens = tokenizer.encode(text, max_length=512)\n",
    "    tokens_list.append(tokens)\n",
    "\n",
    "tokens_len = []\n",
    "for text_len in replace_finding_lst:\n",
    "    tokens_len.append(len(text_len))\n",
    "\n",
    "sns.histplot(data=tokens_len)\n",
    "plt.xlabel('sequences_len')\n",
    "plt.ylabel('sequences_count')\n",
    "plt.show()\n",
    "\n",
    "cnt = 0\n",
    "for data in tokens_len:\n",
    "    if data > 1500:\n",
    "        cnt += 1\n",
    "print(max(tokens_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 tensor :  (11725, 1805)\n",
      "라벨 tensor :  (11725,)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 진행 = prepadding\n",
    "\n",
    "max_len = 1805\n",
    "\n",
    "tokens_list_padded = pad_sequences(tokens_list, padding=\"pre\", maxlen=max_len)\n",
    "\n",
    "input_value = tokens_list_padded\n",
    "\n",
    "label = merge_data_frame['Finding']\n",
    "\n",
    "print(\"입력 tensor : \", input_value.shape)\n",
    "print(\"라벨 tensor : \", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트레인, 검증 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9380, 1805) (2345, 1805) (9380,) (2345,)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "input_train, input_test, label_train, label_test = train_test_split(input_value, label, test_size=0.2, random_state=seed)  \n",
    "\n",
    "print(input_train.shape, input_test.shape, label_train.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파인튜닝\n",
    " - 하이퍼밴드 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow.keras import layers\\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\\nfrom kerastuner.tuners import Hyperband\\nfrom tensorflow.keras.optimizers import Adam\\n\\nadam = Adam(learning_rate=0.001)\\n\\ndef build_model(hp):\\n    model = medical_LSTM(\\n        vocab_size=vocab_size,\\n        embedding_units=hp.Int(\\'embedding_units\\', min_value=32, max_value=128, step=32),\\n        lstm_units=hp.Int(\\'lstm_units\\', min_value=32, max_value=256, step=32),\\n        dense_input_dim=hp.Int(\\'dense_input_dim\\', min_value=32, max_value=256, step=32),\\n        dense_output_dim=1,\\n        dropout_rate=hp.Float(\\'dropout_rate\\', min_value=0.3, max_value=0.5, step=0.01),\\n        l2_reg_rate=hp.Float(\\'l2_reg_rate\\', min_value=0.001, max_value=0.01, step=0.001)\\n    )\\n    model.compile(optimizer=adam, loss=\\'binary_crossentropy\\', metrics=[\\'accuracy\\'])\\n    return model\\n\\ntuner = Hyperband(\\n    build_model,\\n    objective=\\'val_accuracy\\',\\n    max_epochs=3,\\n    directory=\\'hyperband\\',\\n    project_name=\\'medical_LSTM\\'\\n)\\n\\ntuner.search(input_train, label_train, epochs=3, validation_data=(input_test, label_test))\\nbest_hp = tuner.get_best_hyperparameters(num_trials = 1)[0]\\n\\nprint(f\"embedding 유닛 수 : {best_hp.get(\\'embedding_units\\')}\")\\nprint(f\"lstm 유닛 수 : {best_hp.get(\\'lstm_units\\')}\")\\nprint(f\"완전 밀집층 차원 수 : {best_hp.get(\\'dense_input_dim\\')}\")\\nprint(f\"dropout_rate : {best_hp.get(\\'dropout_rate\\')}\")\\nprint(f\"l2_reg_rate : {best_hp.get(\\'l2_reg_rate\\')}\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = medical_LSTM(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_units=hp.Int('embedding_units', min_value=32, max_value=128, step=32),\n",
    "        lstm_units=hp.Int('lstm_units', min_value=32, max_value=256, step=32),\n",
    "        dense_input_dim=hp.Int('dense_input_dim', min_value=32, max_value=256, step=32),\n",
    "        dense_output_dim=1,\n",
    "        dropout_rate=hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.01),\n",
    "        l2_reg_rate=hp.Float('l2_reg_rate', min_value=0.001, max_value=0.01, step=0.001)\n",
    "    )\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=3,\n",
    "    directory='hyperband',\n",
    "    project_name='medical_LSTM'\n",
    ")\n",
    "\n",
    "tuner.search(input_train, label_train, epochs=3, validation_data=(input_test, label_test))\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"embedding 유닛 수 : {best_hp.get('embedding_units')}\")\n",
    "print(f\"lstm 유닛 수 : {best_hp.get('lstm_units')}\")\n",
    "print(f\"완전 밀집층 차원 수 : {best_hp.get('dense_input_dim')}\")\n",
    "print(f\"dropout_rate : {best_hp.get('dropout_rate')}\")\n",
    "print(f\"l2_reg_rate : {best_hp.get('l2_reg_rate')}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단방향 lstm 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sub_lstm(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_units, lstm_units):\n",
    "        super(sub_lstm, self).__init__()\n",
    "\n",
    "        self.embedding_layer = Embedding(vocab_size, embedding_units)\n",
    "\n",
    "        self.lstm_layer = LSTM(lstm_units)\n",
    "\n",
    "        self.output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "\n",
    "        x = self.embedding_layer(inputs)\n",
    "\n",
    "        x = self.lstm_layer(x)\n",
    "\n",
    "        outputs = self.output_layer(x)\n",
    "\n",
    "        return outputs            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 빌드 및 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sub_lstm_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  2783616   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               multiple                  16512     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               multiple                  8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,808,481\n",
      "Trainable params: 2,808,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "adam = Adam(learning_rate=0.01)\n",
    "\n",
    "embedding_units = 96\n",
    "lstm_units = 32\n",
    "\n",
    "sub_model = sub_lstm(\n",
    "    vocab_size= vocab_size,\n",
    "    embedding_units= embedding_units,\n",
    "    lstm_units= lstm_units\n",
    ")\n",
    "\n",
    "sub_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "sub_model.build(input_shape=input_train.shape)\n",
    "sub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 22/294 [=>............................] - ETA: 9:00 - loss: 0.6951 - accuracy: 0.5483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      3\u001b[0m earlystop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msub_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearlystop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "sub_model.fit(x = input_train, \n",
    "              y = label_train,\n",
    "              validation_data=(input_test, label_test),\n",
    "              epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 양방향 LSTM 모델 클래스 정의\n",
    " - 참고 레퍼런스 https://keras.io/api/layers/recurrent_layers/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class medical_LSTM(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_units, lstm_units):\n",
    "        super(medical_LSTM, self).__init__()\n",
    "\n",
    "        self.embedding_layer = Embedding(vocab_size, embedding_units)\n",
    "\n",
    "        self.first_lstm = Bidirectional(LSTM(lstm_units))\n",
    "\n",
    "        self.first_dense = Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "\n",
    "        embedding_output = self.embedding_layer(inputs)\n",
    "\n",
    "        first_lstm_output = self.first_lstm(embedding_output)\n",
    "\n",
    "        first_dense_outputs = self.first_dense(first_lstm_output)\n",
    "\n",
    "        return first_dense_outputs       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 컴파일\n",
    " - 최적화 도구 adam learning_rate = 0.01\n",
    " - 콜백함수 레퍼런스 : https://deep-deep-deep.tistory.com/1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 256\n",
    "word_size = tokenizer.vocab_size\n",
    "embedding_units = 768 # BERT Base의 차원\n",
    "final_output_dim = 1\n",
    "adam = Adam(learning_rate=0.01)\n",
    "\n",
    "model = medical_LSTM(\n",
    "            vocab_size = word_size,\n",
    "            embedding_units= embedding_units,\n",
    "            lstm_units = lstm_units)\n",
    "\n",
    "model.compile(optimizer = adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"medical_lstm_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     multiple                  22268928  \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  multiple                 2099200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,368,641\n",
      "Trainable params: 24,368,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(input_train.shape))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 61518s 261s/step - loss: nan - accuracy: 0.4915 - val_loss: nan - val_accuracy: 0.4675\n",
      "Epoch 2/50\n",
      " 11/235 [>.............................] - ETA: 17:03:51 - loss: nan - accuracy: 0.5710"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=4)\n",
    "\n",
    "record = model.fit(\n",
    "    input_train,\n",
    "    label_train,\n",
    "    epochs = 50,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성능 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에포크 별 정확도 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_graph(history, name):\n",
    "\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(1, len(val_acc)+1)\n",
    "\n",
    "  plt.title(f'{name} Validation accuracy and loss')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.xlabel('epochs')\n",
    "  plt.ylabel('performance_score')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "draw_graph(record, 'two_layer_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- roc-curve\n",
    "    - 모델의 전반적인 성능을 하나의 값으로 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(model, X_val, y_val):\n",
    "    \n",
    "    y_pred_proba = model.predict(X_val).ravel()  # ravel()로 1D 배열로 변환\n",
    "\n",
    "    # ROC 곡선 계산\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "\n",
    "    # AUC 계산\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # ROC 곡선 그리기\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(model, input_test, label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
